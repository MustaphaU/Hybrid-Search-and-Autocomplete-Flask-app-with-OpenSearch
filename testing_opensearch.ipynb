{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d097ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9315af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c5a066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sparse vector from dense vectors with shape batch_size * seq_len * vocab_size\n",
    "def get_sparse_vector(feature, output):\n",
    "    values, _ = torch.max(output*feature[\"attention_mask\"].unsqueeze(-1), dim=1)\n",
    "    values = torch.log(1 + torch.relu(values))\n",
    "    values[:,special_token_ids] = 0\n",
    "    return values\n",
    "    \n",
    "# transform the sparse vector to a dict of (token, weight)\n",
    "def transform_sparse_vector_to_dict(sparse_vector):\n",
    "    sample_indices,token_indices=torch.nonzero(sparse_vector,as_tuple=True)\n",
    "    non_zero_values = sparse_vector[(sample_indices,token_indices)].tolist()\n",
    "    number_of_tokens_for_each_sample = torch.bincount(sample_indices).cpu().tolist()\n",
    "    tokens = [transform_sparse_vector_to_dict.id_to_token[_id] for _id in token_indices.tolist()]\n",
    "\n",
    "    output = []\n",
    "    end_idxs = list(itertools.accumulate([0]+number_of_tokens_for_each_sample))\n",
    "    for i in range(len(end_idxs)-1):\n",
    "        token_strings = tokens[end_idxs[i]:end_idxs[i+1]]\n",
    "        weights = non_zero_values[end_idxs[i]:end_idxs[i+1]]\n",
    "        output.append(dict(zip(token_strings, weights)))\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "196c9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"opensearch-project/opensearch-neural-sparse-encoding-v1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"opensearch-project/opensearch-neural-sparse-encoding-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7fb2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the special tokens and id_to_token transform for post-process\n",
    "special_token_ids = [tokenizer.vocab[token] for token in tokenizer.special_tokens_map.values()]\n",
    "get_sparse_vector.special_token_ids = special_token_ids\n",
    "id_to_token = [\"\" for i in range(tokenizer.vocab_size)]\n",
    "for token, _id in tokenizer.vocab.items():\n",
    "    id_to_token[_id] = token\n",
    "transform_sparse_vector_to_dict.id_to_token = id_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc507b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.3298, grad_fn=<DotBackward0>)\n",
      "score in query: 2.9262, score in document: 2.1335, token: ny\n",
      "score in query: 2.5206, score in document: 1.5277, token: weather\n",
      "score in query: 2.0373, score in document: 2.3489, token: york\n",
      "score in query: 1.5786, score in document: 0.8752, token: cool\n",
      "score in query: 1.4636, score in document: 1.5132, token: current\n",
      "score in query: 0.7761, score in document: 0.8860, token: season\n",
      "score in query: 0.7560, score in document: 0.6726, token: 2020\n",
      "score in query: 0.7222, score in document: 0.6292, token: summer\n",
      "score in query: 0.6888, score in document: 0.6419, token: nina\n",
      "score in query: 0.6451, score in document: 0.8200, token: storm\n",
      "score in query: 0.4698, score in document: 0.7635, token: brooklyn\n",
      "score in query: 0.4562, score in document: 0.1208, token: julian\n",
      "score in query: 0.3484, score in document: 0.3903, token: wow\n",
      "score in query: 0.3439, score in document: 0.4160, token: usa\n",
      "score in query: 0.2751, score in document: 0.8260, token: manhattan\n",
      "score in query: 0.2013, score in document: 0.7735, token: fog\n",
      "score in query: 0.1989, score in document: 0.2961, token: mood\n",
      "score in query: 0.1653, score in document: 0.3437, token: climate\n",
      "score in query: 0.1191, score in document: 0.1533, token: nature\n",
      "score in query: 0.0665, score in document: 0.0599, token: temperature\n",
      "score in query: 0.0552, score in document: 0.3396, token: windy\n"
     ]
    }
   ],
   "source": [
    "query = \"What's the weather in ny now?\"\n",
    "document = \"Currently New York is rainy.\"\n",
    "\n",
    "# encode the query & document\n",
    "feature = tokenizer([query, document], padding=True, truncation=True, return_tensors='pt', return_token_type_ids=False)\n",
    "output = model(**feature)[0]\n",
    "sparse_vector = get_sparse_vector(feature, output)\n",
    "\n",
    "# get similarity score\n",
    "sim_score = torch.matmul(sparse_vector[0],sparse_vector[1])\n",
    "print(sim_score)   # tensor(22.3299, grad_fn=<DotBackward0>)\n",
    "\n",
    "\n",
    "query_token_weight, document_query_token_weight = transform_sparse_vector_to_dict(sparse_vector)\n",
    "for token in sorted(query_token_weight, key=lambda x:query_token_weight[x], reverse=True):\n",
    "    if token in document_query_token_weight:\n",
    "        print(\"score in query: %.4f, score in document: %.4f, token: %s\"%(query_token_weight[token],document_query_token_weight[token],token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5358a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'now': 2.2065000534057617,\n",
       " 'season': 0.7760677337646484,\n",
       " 'here': 0.026180144399404526,\n",
       " 'air': 0.14392752945423126,\n",
       " 'april': 0.03711361065506935,\n",
       " 'york': 2.0373146533966064,\n",
       " 'already': 0.03775929659605026,\n",
       " 'summer': 0.7222039699554443,\n",
       " 'today': 0.25874048471450806,\n",
       " 'change': 0.09803194552659988,\n",
       " 'news': 0.3427507281303406,\n",
       " 'current': 1.4635943174362183,\n",
       " 'future': 0.001597201102413237,\n",
       " 'sun': 0.14983253180980682,\n",
       " 'martin': 0.04427485167980194,\n",
       " 'nature': 0.11914681643247604,\n",
       " 'travel': 0.28682243824005127,\n",
       " 'tonight': 0.15597288310527802,\n",
       " 'usa': 0.34385496377944946,\n",
       " 'storm': 0.64512699842453,\n",
       " '##ius': 0.05066607519984245,\n",
       " 'weather': 2.5205931663513184,\n",
       " 'cool': 1.5786479711532593,\n",
       " 'climate': 0.16530534625053406,\n",
       " 'temperature': 0.06651061773300171,\n",
       " 'ny': 2.926173210144043,\n",
       " 'julian': 0.4562440812587738,\n",
       " 'brooklyn': 0.46979716420173645,\n",
       " 'mood': 0.19892123341560364,\n",
       " 'milan': 0.06909207999706268,\n",
       " 'manhattan': 0.27505552768707275,\n",
       " 'nina': 0.6887561678886414,\n",
       " 'fog': 0.2013213187456131,\n",
       " 'wow': 0.34839779138565063,\n",
       " '2020': 0.7559694647789001,\n",
       " 'forecast': 0.05371301993727684,\n",
       " 'windy': 0.05521073937416077}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_token_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec3a0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"summary of the pages\"\n",
    "encode_query_1 = tokenizer(query_1, return_tensors='pt', truncation=True, padding=True)\n",
    "output_1 = model(**encode_query_1)[0]\n",
    "sparse_vector_1 = get_sparse_vector(encode_query_1, output_1)\n",
    "document_query_token_weight_1 = transform_sparse_vector_to_dict(sparse_vector_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e54d7a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'.': 0.09795466810464859,\n",
       "  'the': 0.9895220994949341,\n",
       "  'of': 0.5942500233650208,\n",
       "  'these': 0.0709637925028801,\n",
       "  'book': 0.45201361179351807,\n",
       "  'main': 0.16776703298091888,\n",
       "  'story': 0.5015198588371277,\n",
       "  'written': 0.09777490049600601,\n",
       "  'hall': 0.10336891561746597,\n",
       "  'various': 0.15453986823558807,\n",
       "  'total': 0.4604087173938751,\n",
       "  'information': 0.11041329056024551,\n",
       "  'seven': 0.2504394054412842,\n",
       "  'table': 0.5144628286361694,\n",
       "  'list': 0.5308113098144531,\n",
       "  'section': 0.29919686913490295,\n",
       "  'novel': 0.21108883619308472,\n",
       "  'chapter': 0.46096885204315186,\n",
       "  'report': 0.16256111860275269,\n",
       "  'view': 0.02961583063006401,\n",
       "  'structure': 0.159208282828331,\n",
       "  'review': 0.32896003127098083,\n",
       "  'chart': 0.6405640244483948,\n",
       "  'article': 0.32595589756965637,\n",
       "  'sides': 0.5633036494255066,\n",
       "  'literature': 0.10077744722366333,\n",
       "  'page': 2.215363025665283,\n",
       "  'analysis': 0.23568813502788544,\n",
       "  'content': 0.07434964179992676,\n",
       "  'eric': 0.2624856233596802,\n",
       "  'circle': 0.1595962643623352,\n",
       "  'brief': 0.9064968824386597,\n",
       "  'map': 0.13684679567813873,\n",
       "  'plot': 0.6308932900428772,\n",
       "  'pages': 2.718653917312622,\n",
       "  'parallel': 0.02000723034143448,\n",
       "  'poem': 0.274784117937088,\n",
       "  'document': 0.32810381054878235,\n",
       "  'description': 0.4326840937137604,\n",
       "  'detail': 0.5826897621154785,\n",
       "  'sample': 0.12978969514369965,\n",
       "  'sum': 1.1032335758209229,\n",
       "  '##mar': 0.08052097260951996,\n",
       "  'edmund': 0.07518969476222992,\n",
       "  'citation': 0.45684927701950073,\n",
       "  'pdf': 0.02493458427488804,\n",
       "  'chronicles': 0.2620607316493988,\n",
       "  'bart': 0.0405251681804657,\n",
       "  'breakdown': 0.1258774995803833,\n",
       "  'summary': 2.9779927730560303,\n",
       "  'outline': 0.20360995829105377,\n",
       "  'timeline': 0.27244511246681213,\n",
       "  'overview': 0.4617987275123596}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_query_token_weight_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335cf05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
